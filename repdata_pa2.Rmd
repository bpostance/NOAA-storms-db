```{r knitrSetup, include=FALSE}
opts_knit$set(root.dir = 'C:/Users/Paulo Jean/Documents/GitHub/RepData_PeerAssessment2/')
```
# Analysis of NOAA's Storm Events Database: Preparing for Severe Weather Events

## Synopsis
This document provides an analysis of U.S. National Oceanic and Atmospheric Administration's (NOAA) [Storm Events Database](http://www.ncdc.noaa.gov/stormevents/) in order to address the question of which major weather events are most harmful with respect to population health and/or have the greatest economic consequences. It's the result of the second assignment from the Coursera's Reproducible Research online course.

## Data files

The main data file used in this analysis is a 47Mb comma-separated-value file compressed via the bzip2 algorithm that can be downloaded from the course web site.
* Main data file: [repdata data StormData.csv.bz2](https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2)

Additionally, we've used two more files that allowed us to 1) map inconsistent event type descriptions to the limited list of 48 event types, as defined in NOAA's National Weather Service (NWS) Directive 10-1605 and 2) adjust economic damages for inflation. These files are available at this GitHub [public repository](https://github.com/pjpjean/RepData_PeerAssessment2):
* [evtypes-directive-10-1605.csv](https://raw.githubusercontent.com/pjpjean/RepData_PeerAssessment2/master/evtypes-directive-10-1605.csv): a manually built mapping from the 985 different event types in the original data file to the NWS's 48-event types list, according to (my best judgment of) Directive 10-1605 guidelines.

* [bls-cpi-1950-2013.csv](https://raw.githubusercontent.com/pjpjean/RepData_PeerAssessment2/master/bls-cpi-1950-2013.csv): Average Consumer Price Index for all calendar years in the 1950-2013 period, adjusted relatively to 1982-84 (index=100). These indexes were download from the Bureau Labor Statistics (BLS) [website](http://data.bls.gov/pdq/SurveyOutputServlet), with the following parameters: **Series ID**, CUUR0000SA0; **Year range**: 1950-2013; **One Time period**: Annual Data; **Output format**: Text, comma delimited.


## Data processing
We begin by loading the main data file into R. Because it's a bzip2 compressed file,  we have to create a bzip2 file connection and pass it to `read.csv()` instead of just the filename. We split the reading in two parts in order to select just the columns we need for our analysis.


```{r reading, cache=TRUE}
# Read only the first line to get columns names (to be able to select just a few
# of them when reading the full dataset). Notice the bzip2 file connection we
# create and close just after using it.
filecon = bzfile("repdata-data-StormData.csv.bz2", "r")
col.names = colnames(read.csv(filecon, nrows=1))
# If we don't close this connection now, next call to read.csv() will resume 
# from where it stopped, but we don't want this.
close(filecon)

# define needed columns
cols.to.read = c("BGN_DATE", "COUNTY", "STATE", "EVTYPE", "FATALITIES", 
                 "INJURIES", "PROPDMG", "PROPDMGEXP", "CROPDMG", "CROPDMGEXP")

# Read file from the beginning (new connection), keeping just the needed columns.
filecon = bzfile("repdata-data-StormData.csv.bz2", "r")
storm = read.csv(filecon, colClasses=c("NULL", NA)[(col.names %in% cols.to.read)+1])
close(filecon)

```

Let's take a look at our data.
```{r firstlook}
str(storm)
```

#### Cleaning and tranforming the data
This data definitely needs some tidying. The more important things we'd want to change are:
* `BGN_DATE` as a factor: we think that a **date** type would be more appropriate, because it'll make it easier to aggregate and summarize on specific periods of time.

```{r transformdate, cache=TRUE}
storm$BGN_DATE = strptime(storm$BGN_DATE, "%m/%d/%Y %H:%M:%S")
```

* `EVTYPE` as a 985-level factor: it seems that there is a lot of redudancy (or mistakes) in these event type descriptions. According to [NOAA's website](http://www.ncdc.noaa.gov/stormevents/details.jsp?type=eventtype), from 1996 to present, only 48 event types are defined by NWS Directive 10-1605. We'd want to translate or map this gigantic list of event types into NWS's latest list.

```{r transformevtype, cache=TRUE}
evtype <- read.csv("evtypes-directive-10-1605.csv", stringsAsFactors = FALSE)
storm$EVTYPE48 = factor(evtype$EVTYPE48[match(levels(storm$EVTYPE)[storm$EVTYPE], evtype$EVTYPE)])
levels(storm$EVTYPE48)
```

* `PROPDMG` and `CROPDMG` with multiple scales: damage magnitudes are expressed in a separate variable (`PROPDMGEXP` and `CROPDMGEXP`, respectively). We should normalize them (to the same scale), otherwise it would not be straighforward to compare damage values in different events and dates.

We start by capitalizing all magnitude codes. It'll make the following steps easier.
```{r transformdamages}
# capitalize all 1-letter magnitude codes 
storm$PROPDMGEXP = toupper(storm$PROPDMGEXP)
storm$CROPDMGEXP = toupper(storm$CROPDMGEXP)
```

Before normalizing, we have to check whether there are invalid values in the magnitude variables.
```{r checkvalidmag}
# check invalid codes in property damages
valid.mag = c("", "H", "K", "M", "B")
with(storm[!storm$PROPDMGEXP %in% valid.mag,], 
     table(factor(PROPDMGEXP), format(BGN_DATE, "%Y")))
# check invalid codes in crop damages
with(storm[!storm$CROPDMGEXP %in% valid.mag,], 
     table(factor(CROPDMGEXP), format(BGN_DATE, "%Y")))
```
We see that, apart from one observation in 2011, all invalid magnitude codes are from the 1993-1995 period when, according to [NOAA's website](http://www.ncdc.noaa.gov/stormevents/details.jsp?type=eventtype), events were extracted from Unformatted Text files, a task known to be more prone to error. We'll leave them alone and consider all to be invalid. That means that their normalized value will be set to `NA`.

We're going to create two more variables to store the normalized values.
```{r normdamages}
magnitude = 10^c(0,2,3,6,9)
storm$nPROPDMG = storm$PROPDMG * magnitude[match(storm$PROPDMGEXP, valid.mag)]
storm$nCROPDMG = storm$CROPDMG * magnitude[match(storm$CROPDMGEXP, valid.mag)]
```

Now we need to adjust them for inflation, using BLS Consumer Price Index data, mentioned in the **Data files** section.
```{r inflation}
# read CPI data
cpi = read.csv("bls-cpi-1950-2013.csv", skip=13, colClasses=c("integer", "numeric", "NULL"))
# get last index
last.cpi = tail(cpi, 1)$Annual
# calculate each row's inflation index
adj.index = last.cpi/cpi[match(storm$BGN_DATE$year+1900, cpi$Year),"Annual"]
# apply them
storm$nPROPDMG = floor(storm$nPROPDMG * adj.index)
storm$nCROPDMG = floor(storm$nCROPDMG * adj.index)
```

One last step would be to generate an aggregate dataset, with annual totals. That will be the dataset used in our analysis.
```{r endpreparation, cache=TRUE}
storm.agg = aggregate(cbind(FATALITIES, INJURIES, nPROPDMG, nCROPDMG) ~ 
                        BGN_DATE$year + EVTYPE48 + STATE, data=storm, sum)
names(storm.agg)[1] = "YEAR"
storm.agg$YEAR = storm.agg$YEAR + 1900
```
## Analysis
As mentioned in the NOAA's website, until 1992, only tornado, thunderstorm wind and hail events found their way into the database. Let's see what we have in our dataset.
```{r pre1993}
pre1993 = aggregate(cbind(FATALITIES, INJURIES, nPROPDMG, nCROPDMG) ~ EVTYPE48, data=storm.agg[storm.agg$YEAR<1993,], sum)
pre1993
```

As we can see, until 1992, property damages related to 'Tornado' events amount to   `r sprintf("$%0.1f",pre1993[pre1993$EVTYPE48=="Tornado",]$nPROPDMG/10^9)` billion. This is more than 19% of total property damages of all event types in the whole period. Tornado pre-1993 data also represents 26.5% of all fatalities and 48% of all injuries, as we show below.
```{r tornadorel}
metrics = c("FATALITIES", "INJURIES", "nPROPDMG", "nCROPDMG")
pre1993[pre1993$EVTYPE48=="Tornado", metrics]/colSums(storm.agg[metrics])
```

Any attempt of making an unbiased analysis should leave pre-1993 data out and that's what we're going to do.

```{r post1993}
storm.agg.93 = subset(storm.agg, YEAR>=1993)
```

### Events harmful to population health
Now, we start to analyze the type of events most harmful to population health, according to 1993 and forward storm data.
```{r harmful}
harmful = aggregate(cbind(FATALITIES, INJURIES) ~ EVTYPE48, data=storm.agg.93, sum)
# ordering by FATALITIES and INJURIES
most.harmful.5 = lapply(c("FATALITIES", "INJURIES"),
                        function(n) harmful[
                          order(harmful[n], decreasing=TRUE)[1:5],
                          c("EVTYPE48",n)])
most.harmful.5
```

We can see that, in the period including and after 1993, 'Tornado' was the event that caused more injuries, as most of us would pehaps expect.

What came as a surprise is that 'Excessive Heat' caused more fatalities in the same period (followed by 'Tornado' events). If we add to this number those 'Heat'-caused fatalities (3rd line of first list item), we'll have more than 3,100 heat-related fatalities, almost twice as much as 'Tornado' fatalities.

Let's investigate this a little further.

```{r heatrelated, fig.width=9}
heat.related = storm.agg.93$EVTYPE48=="Excessive Heat" | 
  storm.agg.93$EVTYPE48=="Heat"

library(ggplot2)
ggplot(storm.agg.93[heat.related,], aes(x=as.factor(YEAR), y=FATALITIES)) + 
  geom_bar(stat="identity", fill="darkolivegreen3") +
  labs(title= "Heat-related fatalities (1993-2011)", x="Year",
     y=expression("Fatalities")) +
  guides(fill=FALSE) +
  theme_minimal() +
  theme(plot.title=element_text(size=18, face="bold"),
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank())
```

Look at the barplot above. Why is the number of 1995 heat-related fatalities so high? Let's check which states had more fatalities that year.

```{r heatrelated_states}
states.heat = aggregate(FATALITIES ~ STATE, data=subset(storm.agg.93, heat.related & YEAR==1995), sum)
states.heat = states.heat[order(states.heat$FATALITIES, decreasing=TRUE),]
head(states.heat, 5)
```
We can see that Illinois was the state with the greatest number of heat-related fatalities in 1995. Searching on the internet, we find that it corresponds to the so-called "1995 Chicago heat wave". According to [Wikipedia](http://en.wikipedia.org/wiki/1995_Chicago_heat_wave), this heat wave "led to approximately 750 heat-related deaths in Chicago over a period of five days. Most of the victims of the heatwave were elderly poor residents of the inner city, who could not afford air conditioning and did not open windows or sleep outside for fear of crime."

Getting back to our list, we'll have flood-like events, thunderstorm winds and lightning events, besides heat and tornadoes, as the most harmful events to population health.

```r
most.harmful.5
```

### Events with the greatest economic consequences
We can apply a similar approach to find the events that cause more damages to property and crop in the 1993-2011 period.

```{r economic}
econ.cons = aggregate(cbind(nPROPDMG, nCROPDMG) ~ EVTYPE48, data=storm.agg.93, sum)
# ordering by FATALITIES and INJURIES
econ.cons.5 = lapply(c("nPROPDMG", "nCROPDMG"),
                        function(n) econ.cons[
                          order(econ.cons[n], decreasing=TRUE)[1:5],
                          c("EVTYPE48",n)])
econ.cons.5
```

'Flood' and 'Hurricane (Typhoon)' come up as the most dangerous weather events to property. They have their evil share in crop damages too.

propdmg.top5 = as.character(econ.cons.5[[1]]$EVTYPE48)
propdmg.agg = aggregate(nPROPDMG ~ EVTYPE48 + YEAR, data=subset(storm.agg.93, EVTYPE48 %in% propdmg.top5), sum)
ggplot(propdmg.agg, aes(x=as.factor(YEAR), y=nPROPDMG, group=EVTYPE48, color=EVTYPE48)) + 
  geom_line() + scale_y_log10()


cropdmg.top5 = as.character(econ.cons.5[[2]]$EVTYPE48)


## Results
